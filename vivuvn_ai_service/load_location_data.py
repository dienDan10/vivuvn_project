#!/usr/bin/env python3
"""
Optimized script to load location data from location_data.json into Pinecone
with chunking and minimal metadata approach.

This script uses the new EmbeddingService with LangChain chunking for better
semantic search and 90% smaller metadata for cost optimization.
"""

import asyncio
import structlog
import os
import sys
from pathlib import Path

# Add the app directory to the Python path
current_dir = Path(__file__).parent
app_dir = current_dir / "app"
sys.path.insert(0, str(app_dir))

from app.utils.data_loader import get_data_loader

# Configure structlog for script
structlog.configure(
    processors=[
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.dev.ConsoleRenderer()  # Human-readable output for scripts
    ],
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)
logger = structlog.get_logger(__name__)


async def main():
    """Main function to load location data with optimized chunking."""
    try:
        logger.info("Starting optimized location data loading process...")
        
        # Path to the location data file - using project's local data
        location_data_path = "data/location_data.json"
        
        # Get data loader instance
        data_loader = get_data_loader()
        
        # Vector index is automatically initialized when services are created
        logger.info("Vector services initialized (index auto-created if needed)")
        
        # Get chunking stats before loading
        logger.info("Chunking configuration:")
        chunking_stats = await data_loader.get_chunking_stats()
        for key, value in chunking_stats.get('embedding_service', {}).items():
            logger.info(f"  {key}: {value}")
        
        # Load places from location data with chunking
        logger.info("Loading places from location_data.json with optimized chunking...")
        logger.info("This will create multiple vectors per place if descriptions are long...")
        
        loaded_count = await data_loader.load_places_from_json(location_data_path)
        
        logger.info(f"Successfully processed {loaded_count} places")
        
        # Get final statistics
        from app.services.pinecone_service import get_pinecone_service
        pinecone_service = get_pinecone_service()
        stats = await pinecone_service.get_index_stats()
        
        logger.info("Final Pinecone index statistics:")
        logger.info(f"  Total vectors: {stats.get('total_vectors', 'unknown')}")
        logger.info(f"  Dimension: {stats.get('dimension', 'unknown')}")
        logger.info(f"  Index fullness: {stats.get('index_fullness', 'unknown')}")
        
        # Calculate chunking efficiency
        if stats.get('total_vectors') and loaded_count:
            avg_chunks_per_place = stats['total_vectors'] / loaded_count
            logger.info(f"  Average chunks per place: {avg_chunks_per_place:.1f}")
        
        logger.info("\nðŸŽ‰ Optimized location data loading completed successfully!")
        logger.info("ðŸ“Š Benefits of the new approach:")
        logger.info("  â€¢ Better semantic search with chunking")
        logger.info("  â€¢ 90% smaller metadata (minimal approach)")
        logger.info("  â€¢ Faster queries and lower costs")
        logger.info("  â€¢ Vietnamese-optimized embeddings")
        
    except Exception as e:
        logger.error(f"Error loading location data: {e}")
        raise


if __name__ == "__main__":
    # Run the async main function
    asyncio.run(main())